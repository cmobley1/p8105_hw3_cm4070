p8105\_hw3\_cm4070
================

``` r
library(tidyverse)
```

    ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──

    ## ✓ ggplot2 3.3.5     ✓ purrr   0.3.4
    ## ✓ tibble  3.1.4     ✓ dplyr   1.0.7
    ## ✓ tidyr   1.1.3     ✓ stringr 1.4.0
    ## ✓ readr   2.0.1     ✓ forcats 0.5.1

    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(patchwork)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6, 
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options( 
  ggplot2.continuous.colour = "viridis", 
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Question 1

### Load data

``` r
library(p8105.datasets)

data("instacart") 
```

There are 1384617 observations and 15 variables, and key variable names
are order\_id, product\_id, add\_to\_cart\_order, reordered, user\_id,
eval\_set, order\_number, order\_dow, order\_hour\_of\_day,
days\_since\_prior\_order, product\_name, aisle\_id, department\_id,
aisle, department in the `instacart` data.

### Describe aisles with plot

``` r
instacart %>% 
  count(aisle, name = "n_columns") %>% 
  arrange(desc(n_columns)) %>% 
  filter(n_columns > 10000) %>% 
  mutate(aisle = forcats::fct_reorder(aisle, n_columns)) %>% 
  ggplot(aes(x = n_columns, y = aisle, color = aisle)) + geom_point() +
  labs(title = "Aisles' Popularity plot", 
    x = "number of items ordered in each aisle",
    y = "aisle name",
    caption = "Data from “The Instacart Online Grocery Shopping Dataset 2017"
    ) +
    scale_x_continuous(
      limits = c(10000, 170000))
```

<img src="p8105_hw3_cm4070_files/figure-gfm/unnamed-chunk-2-1.png" width="90%" />

There are approximately 134 aisles. The aisles most ordered from are
fresh vegetables, fresh fruits, and packaged vegetables and fruits. We
can see this in the above plot where we see the number of items ordered
in each aisle with its respective name and the values at approximately
150000 values are those most popular.

### Make a table with three most popular items within 3 aisles

``` r
popular_items =
  instacart %>%
  group_by(aisle, product_name) %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  summarize(n_obs = n()) %>%
  arrange(desc(n_obs)) %>%
  slice(1:3) %>%
  knitr::kable(digits = 1)
```

    ## `summarise()` has grouped output by 'aisle'. You can override using the `.groups` argument.

``` r
popular_items
```

| aisle                      | product\_name                                 | n\_obs |
|:---------------------------|:----------------------------------------------|-------:|
| baking ingredients         | Light Brown Sugar                             |    499 |
| baking ingredients         | Pure Baking Soda                              |    387 |
| baking ingredients         | Cane Sugar                                    |    336 |
| dog food care              | Snack Sticks Chicken & Rice Recipe Dog Treats |     30 |
| dog food care              | Organix Chicken & Brown Rice Recipe           |     28 |
| dog food care              | Small Dog Biscuits                            |     26 |
| packaged vegetables fruits | Organic Baby Spinach                          |   9784 |
| packaged vegetables fruits | Organic Raspberries                           |   5546 |
| packaged vegetables fruits | Organic Blueberries                           |   4966 |

This table shows the top 3 most ordered products within baking
ingredients, dog food care, and packaged vegetable fruits aisles, and
number of times they were ordered.

### Mean hour table - Pink Lady Apples and Coffee Ice Cream

``` r
instacart %>%
  select(product_name, order_dow, order_hour_of_day) %>%
  filter(product_name == "Pink Lady Apples" | product_name == "Coffee Ice Cream") %>%
  group_by(product_name, order_dow) %>%
  summarize(
    mean_hour_of_day = mean(order_hour_of_day)) %>%
  mutate(order_dow = 
           recode(order_dow,
                  "0" = "monday", "1" = "tuesday","2" = "wednesday", "3" = "thursday", "4" = "friday", "5" = "saturday","6" = "sunday")) %>%
    pivot_wider(
    names_from = order_dow,
    values_from = mean_hour_of_day) %>%
    knitr::kable(digits = 1)
```

    ## `summarise()` has grouped output by 'product_name'. You can override using the `.groups` argument.

| product\_name    | monday | tuesday | wednesday | thursday | friday | saturday | sunday |
|:-----------------|-------:|--------:|----------:|---------:|-------:|---------:|-------:|
| Coffee Ice Cream |   13.8 |    14.3 |      15.4 |     15.3 |   15.2 |     12.3 |   13.8 |
| Pink Lady Apples |   13.4 |    11.4 |      11.7 |     14.2 |   11.6 |     12.8 |   11.9 |

This table shows the mean hour of the day at which Pink Lady Apples and
Coffee Ice Cream are ordered on each day of the week.

## Question 2

### Clean the BRFSS Data set & build plots

``` r
brfss_df = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic %in% "Overall Health" & response %in% c("Excellent", "Very good", "Good", "Fair", "Poor")) %>% 
  mutate(response = forcats::fct_relevel(response, c("Poor", "Fair", "Good", "Very good", "Excellent"))
  )
```

``` r
brfss_df %>%
  filter(year == 2002) %>%
  separate(locationdesc, into = c("state", "county", convert = TRUE)) %>%
  group_by(state, county)  %>%
  distinct(county, .keep_all = TRUE)
```

    ## Warning: Expected 3 pieces. Additional pieces discarded in 65 rows [26, 27, 28,
    ## 29, 30, 56, 67, 68, 69, 70, 71, 72, 73, 74, 75, 91, 92, 93, 94, 95, ...].

    ## # A tibble: 155 × 25
    ## # Groups:   state, county [155]
    ##     year locationabbr state county    `TRUE`       class topic question response
    ##    <int> <chr>        <chr> <chr>     <chr>        <chr> <chr> <chr>    <fct>   
    ##  1  2002 AL           AL    Jefferson County       Heal… Over… How is … Excelle…
    ##  2  2002 AK           AK    Anchorage Municipality Heal… Over… How is … Excelle…
    ##  3  2002 AZ           AZ    Maricopa  County       Heal… Over… How is … Excelle…
    ##  4  2002 AR           AR    Pulaski   County       Heal… Over… How is … Very go…
    ##  5  2002 AZ           AZ    Pima      County       Heal… Over… How is … Excelle…
    ##  6  2002 CA           CA    Los       Angeles      Heal… Over… How is … Excelle…
    ##  7  2002 CO           CO    Adams     County       Heal… Over… How is … Excelle…
    ##  8  2002 CT           CT    Fairfield County       Heal… Over… How is … Very go…
    ##  9  2002 CO           CO    Arapahoe  County       Heal… Over… How is … Excelle…
    ## 10  2002 CO           CO    Denver    County       Heal… Over… How is … Excelle…
    ## # … with 145 more rows, and 16 more variables: sample_size <int>,
    ## #   data_value <dbl>, confidence_limit_low <dbl>, confidence_limit_high <dbl>,
    ## #   display_order <int>, data_value_unit <chr>, data_value_type <chr>,
    ## #   data_value_footnote_symbol <chr>, data_value_footnote <chr>,
    ## #   data_source <chr>, class_id <chr>, topic_id <chr>, location_id <chr>,
    ## #   question_id <chr>, respid <chr>, geo_location <chr>

``` r
brfss_df %>%
  janitor::clean_names() %>% 
  filter(topic %in% "Overall Health" & response %in% c("Excellent", "Very good", "Good", "Fair", "Poor")) %>% 
  mutate(response = forcats::fct_relevel(response, c("Poor", "Fair", "Good", "Very good", "Excellent"))
  ) %>%
  filter(year == 2010) %>%
  separate(locationdesc, into = c("state", "county", convert = TRUE)) %>%
  group_by(state, county)  %>%
  distinct(county, .keep_all = TRUE)
```

    ## Warning: Expected 3 pieces. Additional pieces discarded in 180 rows [51, 52, 53,
    ## 54, 55, 56, 57, 58, 59, 60, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, ...].

    ## # A tibble: 296 × 25
    ## # Groups:   state, county [296]
    ##     year locationabbr state county     `TRUE` class         topic question response
    ##    <int> <chr>        <chr> <chr>      <chr>  <chr>         <chr> <chr>    <fct>   
    ##  1  2010 AL           AL    Jefferson  County Health Status Over… How is … Excelle…
    ##  2  2010 AL           AL    Mobile     County Health Status Over… How is … Excelle…
    ##  3  2010 AL           AL    Tuscaloosa County Health Status Over… How is … Excelle…
    ##  4  2010 AZ           AZ    Maricopa   County Health Status Over… How is … Excelle…
    ##  5  2010 AZ           AZ    Pinal      County Health Status Over… How is … Excelle…
    ##  6  2010 AZ           AZ    Pima       County Health Status Over… How is … Excelle…
    ##  7  2010 AR           AR    Benton     County Health Status Over… How is … Excelle…
    ##  8  2010 AR           AR    Pulaski    County Health Status Over… How is … Excelle…
    ##  9  2010 AR           AR    Washington County Health Status Over… How is … Excelle…
    ## 10  2010 CA           CA    Alameda    County Health Status Over… How is … Excelle…
    ## # … with 286 more rows, and 16 more variables: sample_size <int>,
    ## #   data_value <dbl>, confidence_limit_low <dbl>, confidence_limit_high <dbl>,
    ## #   display_order <int>, data_value_unit <chr>, data_value_type <chr>,
    ## #   data_value_footnote_symbol <chr>, data_value_footnote <chr>,
    ## #   data_source <chr>, class_id <chr>, topic_id <chr>, location_id <chr>,
    ## #   question_id <chr>, respid <chr>, geo_location <chr>

It appears that 3 states in 2002 had more than 7 locations, and in 2010
about 10 had more than 7 locations.

## Question 3

#### Load, tidy, and wrangle the data

``` r
accel_data = 
  read_csv("./accel_data.csv") %>%
  janitor::clean_names() %>%
  rename_with(~str_replace(., "activity_", paste0("minute_"))) %>%
  mutate(weekend_vs_weekday = recode(day, "Friday" = "Weekday", "Monday" = "Weekday", "Tuesday" = "Weekday","Wednesday" = "Weekday", "Thursday" = "Weekday", "Saturday" = "Weekend", "Sunday" = "Weekend"))
```

    ## Rows: 35 Columns: 1443

    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr    (1): day
    ## dbl (1442): week, day_id, activity.1, activity.2, activity.3, activity.4, ac...

    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

The `accel_data` has 35 observations and 1444 variables and key variable
names are week, day\_id, day, minute\_1-minute1400, weekend v.s. weekday
variable. These data tells us about the average physical activity of a
63 year old man wih a BMI of 25 who was diagnosed with congestive heart
failure for every minute of a 24 hour day.

#### Aggregate across minutes for total activity daily

``` r
accel_data %>%
  rowwise() %>%
  mutate(total = sum(across(minute_1:minute_1440))) %>%
  select(day_id, day, total) %>%
  group_by(day) %>%
  summarize(mean(total)) %>%
  knitr::kable(digits = 1)
```

| day       | mean(total) |
|:----------|------------:|
| Friday    |    458342.1 |
| Monday    |    371739.8 |
| Saturday  |    273847.4 |
| Sunday    |    383842.6 |
| Thursday  |    418230.1 |
| Tuesday   |    359847.6 |
| Wednesday |    425954.4 |

There does not appear to be a major pattern to the physical exercise
values across the course of the week. Although, the weekend Saturday
especially appears to have a lower mean physical activity measure than
the other dats, which may indicate that this day is more relaxed and or
the individual was less likely to be wearing his exercise band.

#### Single-panel plot 24hour time period

``` r
accel_data 
```

    ## # A tibble: 35 × 1,444
    ##     week day_id day       minute_1 minute_2 minute_3 minute_4 minute_5 minute_6
    ##    <dbl>  <dbl> <chr>        <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>
    ##  1     1      1 Friday        88.4     82.2     64.4     70.0     75.0     66.3
    ##  2     1      2 Monday         1        1        1        1        1        1  
    ##  3     1      3 Saturday       1        1        1        1        1        1  
    ##  4     1      4 Sunday         1        1        1        1        1        1  
    ##  5     1      5 Thursday      47.4     48.8     46.9     35.8     49.0     44.8
    ##  6     1      6 Tuesday       64.8     59.5     73.7     45.7     42.4     58.4
    ##  7     1      7 Wednesday     71.1    103.      68.5     45.4     37.8     18.3
    ##  8     2      8 Friday       675      542     1010      779      509      106  
    ##  9     2      9 Monday       291      335      393      335      263      675  
    ## 10     2     10 Saturday      64       11        1        1        1        1  
    ## # … with 25 more rows, and 1,435 more variables: minute_7 <dbl>,
    ## #   minute_8 <dbl>, minute_9 <dbl>, minute_10 <dbl>, minute_11 <dbl>,
    ## #   minute_12 <dbl>, minute_13 <dbl>, minute_14 <dbl>, minute_15 <dbl>,
    ## #   minute_16 <dbl>, minute_17 <dbl>, minute_18 <dbl>, minute_19 <dbl>,
    ## #   minute_20 <dbl>, minute_21 <dbl>, minute_22 <dbl>, minute_23 <dbl>,
    ## #   minute_24 <dbl>, minute_25 <dbl>, minute_26 <dbl>, minute_27 <dbl>,
    ## #   minute_28 <dbl>, minute_29 <dbl>, minute_30 <dbl>, minute_31 <dbl>, …
