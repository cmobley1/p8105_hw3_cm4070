---
title: "p8105_hw3_cm4070"
output: github_document
---

```{r loadlibraries_plots}
library(tidyverse)
library(patchwork)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6, 
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options( 
  ggplot2.continuous.colour = "viridis", 
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Question 1

### Load data

```{r}
library(p8105.datasets)

data("instacart") 
```

There are `r nrow(instacart)` observations and `r ncol(instacart)` variables, and key variable names are `r names(instacart)` in the `instacart` data. 

### Describe aisles with plot

```{r}
instacart %>% 
  count(aisle, name = "n_columns") %>% 
  arrange(desc(n_columns)) %>% 
  filter(n_columns > 10000) %>% 
  mutate(aisle = forcats::fct_reorder(aisle, n_columns)) %>% 
  ggplot(aes(x = n_columns, y = aisle, color = aisle)) + geom_point() +
  labs(title = "Aisles' Popularity plot", 
    x = "number of items ordered in each aisle",
    y = "aisle name",
    caption = "Data from â€œThe Instacart Online Grocery Shopping Dataset 2017"
    ) +
    scale_x_continuous(
      limits = c(10000, 170000))
```

There are approximately 134 aisles. The aisles most ordered from are fresh vegetables, fresh fruits, and packaged vegetables and fruits. We can see this in the above plot where we see the number of items ordered in each aisle with its respective name and the values at approximately 150000 values are those most popular.

### Make a table with three most popular items within 3 aisles 

```{r}
popular_items =
  instacart %>%
  group_by(aisle, product_name) %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  summarize(n_obs = n()) %>%
  arrange(desc(n_obs)) %>%
  slice(1:3) %>%
  knitr::kable(digits = 1)
popular_items
```

This table shows the top 3 most ordered products within baking ingredients, dog food care, and packaged vegetable fruits aisles, and number of times they were ordered.

### Mean hour table - Pink Lady Apples and Coffee Ice Cream

```{r}
instacart %>%
  select(product_name, order_dow, order_hour_of_day) %>%
  filter(product_name == "Pink Lady Apples" | product_name == "Coffee Ice Cream") %>%
  group_by(product_name, order_dow) %>%
  summarize(
    mean_hour_of_day = mean(order_hour_of_day)) %>%
  mutate(order_dow = 
           recode(order_dow,
                  "0" = "monday", "1" = "tuesday","2" = "wednesday", "3" = "thursday", "4" = "friday", "5" = "saturday","6" = "sunday")) %>%
    pivot_wider(
    names_from = order_dow,
    values_from = mean_hour_of_day) %>%
    knitr::kable(digits = 1)
```

This table shows the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are 
ordered  on each day of the week. 

## Question 2

### Clean the BRFSS Data set & build plots

```{r}
brfss_df = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic %in% "Overall Health" & response %in% c("Excellent", "Very good", "Good", "Fair", "Poor")) %>% 
  mutate(response = forcats::fct_relevel(response, c("Poor", "Fair", "Good", "Very good", "Excellent"))
  )
```

```{r}
brfss_df %>%
  filter(year == 2002) %>%
  separate(locationdesc, into = c("state", "county", convert = TRUE)) %>%
  group_by(state, county)  %>%
  distinct(county, .keep_all = TRUE)

brfss_df %>%
  janitor::clean_names() %>% 
  filter(topic %in% "Overall Health" & response %in% c("Excellent", "Very good", "Good", "Fair", "Poor")) %>% 
  mutate(response = forcats::fct_relevel(response, c("Poor", "Fair", "Good", "Very good", "Excellent"))
  ) %>%
  filter(year == 2010) %>%
  separate(locationdesc, into = c("state", "county", convert = TRUE)) %>%
  group_by(state, county)  %>%
  distinct(county, .keep_all = TRUE)
```

It appears that 3 states in 2002 had more than 7 locations, and in 2010 about 10 had more than 7 locations.


## Problem 3

#### Load, tidy, and wrangle the data

```{r}
accel_data = 
  read_csv("./accel_data.csv") %>%
  janitor::clean_names() %>%
  rename_with(~str_replace(., "activity_", paste0("minute_"))) %>%
  mutate(weekend_vs_weekday = recode(day, "Friday" = "Weekday", "Monday" = "Weekday", "Tuesday" = "Weekday","Wednesday" = "Weekday", "Thursday" = "Weekday", "Saturday" = "Weekend", "Sunday" = "Weekend"))
```
  
The `accel_data`  has `r nrow(accel_data)` observations and `r ncol(accel_data)` variables and key variable names are week, day_id, day, minute_1-minute1400, weekend v.s. weekday variable. These data tells us about the average physical activity of a 63 year old man wih a BMI of 25 who was diagnosed with congestive heart failure for every minute of a 24 hour day. 

#### Aggregate across minutes for total activity daily

```{r}
accel_data %>%
  rowwise() %>%
  mutate(total = sum(across(minute_1:minute_1440))) %>%
  select(day_id, day, total) %>%
  group_by(day) %>%
  summarize(mean(total)) %>%
  knitr::kable(digits = 1)
```

There does not appear to be a major pattern to the physical exercise values across the course of the week. Although, the weekend Saturday especially appears to have a lower mean physical activity measure than the other dats, which may indicate that this day is more relaxed and or the individual was less likely to be wearing his exercise band. 

#####
